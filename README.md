# EE604_course_project
Deepfake detection using cnn
# ğŸ­ Temporalâ€“Spatial Deepfake Detection using ResNeXt-LSTM and Transformer-Based Fusion Networks

**EE604 Course Project â€” IIT Kanpur**
By: *Sabeeh Muhammed MC*, *Aabha Jalan*, *Diyush S*, *Nikhil N*, *Abhinav Ghosh*

---

## ğŸ§  Overview

This repository contains our implementation for **Temporalâ€“Spatial Deepfake Detection using ResNeXt-LSTM and Transformer-Based Fusion Networks**, developed as part of the *EE604: Machine Learning for Signal Processing* course at IIT Kanpur.

The project investigates how combining **spatial encoders (CNNs)** and **temporal sequence models (RNNs/Transformers)** improves robustness in deepfake video detection.

We evaluate three complementary architectures:

| Architecture                      | Type                | Purpose                                   |
| --------------------------------- | ------------------- | ----------------------------------------- |
| **ResNeXt-LSTM (ours)**           | CNN + LSTM          | Final high-accuracy spatio-temporal model |
| **MesoInception-4 + Transformer** | CNN + Attention     | Lightweight attention-based variant       |
| **MobileNetV2 + GRU**             | Efficient CNN + RNN | Resource-constrained efficient model      |

---

## ğŸ“‚ Repository Structure

```
EE604_Course_Project/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_resnext_lstm.py
â”‚   â”œâ”€â”€ train_meso_transformer.py
â”‚   â”œâ”€â”€ train_mobilenet_gru.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â””â”€â”€ predict_video.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ app/                            # ğŸ”¹ Web interface (Streamlit)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_resnext_lstm.pth
â”‚   â”œâ”€â”€ best_transformer_model.pth
â”‚   â””â”€â”€ best_mobilenetv2_gru.h5
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ pipeline.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â””â”€â”€ qualitative.png
â”‚
â””â”€â”€ report/
    â”œâ”€â”€ Project_Report.pdf
    â”œâ”€â”€ main.tex
    â”œâ”€â”€ main.bib
    â””â”€â”€ figures/
```

---

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/aabhajalan/EE604_course_project.git
cd EE604_course_project
pip install -r requirements.txt
```

For GPU systems, ensure PyTorch and torchvision are installed with CUDA support.

---

## ğŸš€ Training the Models

To train each model variant:

```bash
# Train the final ResNeXt-LSTM model
python src/train_resnext_lstm.py

# Train the MesoInception-4 + Transformer model
python src/train_meso_transformer.py

# Train the MobileNetV2 + GRU model
python src/train_mobilenet_gru.py
```

---

## ğŸ§ª Evaluation

Evaluate a saved checkpoint on the test dataset:

```bash
python src/inference/predict_video.py --model models/best_resnext_lstm.pth --video sample_video.mp4
```

The script outputs:

* Predicted label (Real/Fake)
* Confidence score
* Optional visual overlay if enabled

---



## ğŸ“Š Experimental Results

All experiments were conducted on an NVIDIA T4 GPU with 15 GB VRAM using the **FaceForensics++**, **Celeb-DF v2**, and **DFDC** datasets.

| Model                         |  Accuracy  |    AUC   | F1-Score |
| :---------------------------- | :--------: | :------: | :------: |
| MesoInception-4 + Transformer |   86.8 %   |   0.90   |   0.86   |
| MobileNetV2 + GRU             |   88.4 %   |   0.91   |   0.87   |
| **ResNeXt-LSTM (Ours)**       | **92.7 %** | **0.96** | **0.93** |

### Example Outputs

| Figure                                            | Description                                      |
| ------------------------------------------------- | ------------------------------------------------ |
| ![Confusion Matrix](figures/confusion_matrix.png) | Balanced detection between real and fake classes |
| ![ROC Curve](figures/roc_curve.png)               | AUC = 0.9538                                     |
| ![Attention Map](figures/qualitative.png)         | Model focus on facial regions like eyes and lips |

---

## ğŸ§© Model Insights

* **ResNeXt-LSTM** shows superior class separability and stability in predictions.
* The **Transformer variant** demonstrated the ability to capture long-range frame dependencies.
* The **MobileNetV2 + GRU** offered a practical balance between efficiency and accuracy for edge devices.

---

## ğŸ“¦ Datasets

* [FaceForensics++](https://github.com/ondyari/FaceForensics)
* [Celeb-DF v2](https://github.com/yuezunli/celeb-deepfakeforensics)
* [DFDC Dataset](https://ai.facebook.com/datasets/dfdc)

> âš ï¸ Dataset files are not included in this repository due to size and licensing constraints.

---

## ğŸ‘¨â€ğŸ’» Contributors

| Name                   | Email                                                     |
| ---------------------- | --------------------------------------------------------- | 
| **Sabeeh Muhammed MC** | [saheebm24@iitk.ac.in](mailto:saheebm24@iitk.ac.in)       | 
| **Aabha Jalan**        | [aabhajalan24@iitk.ac.in](mailto:aabhajalan24@iitk.ac.in) | 
| **Diyush S**           | [diyushs24@iitk.ac.in](mailto:diyushs24@iitk.ac.in)       | 
| **Nikhil N**           | [nikhiln23@iitk.ac.in](mailto:nikhiln23@iitk.ac.in)       | 
| **Abhinav Ghosh**      | [abhinavg24@iitk.ac.in](mailto:abhinavg24@iitk.ac.in)     | 


---

## ğŸ“š References

* Piotr Kawa, Piotr Syga. *A Note on Deepfake Detection with Low-Resources.* arXiv preprint arXiv:2006.05183 (2020).
* Abhijit Jadhav et al. *Deepfake Video Detection using ResNeXt Convolutional and LSTM Networks.* GHRCEM Technical Report (2020).
* Mark Sandler et al. *MobileNetV2: Inverted Residuals and Linear Bottlenecks.* arXiv preprint arXiv:1801.04381 (2018).
